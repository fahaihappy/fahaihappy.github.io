<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CS31n学习笔记损失函数与最优化]]></title>
    <url>%2F2018%2F08%2F22%2FCS31n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%89----%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E6%9C%80%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[1、前言 损失函数（Loss function）或者代价函数（Cost function）是用来估量你模型的预测值 $f(x)$ 与真实值 Y 的不一致程度，也就是当前W取值下的不理想程度。它是一个非负实值函数，通常用 $L(Y,f(x))$ 来表示。损失函数越小，模型的鲁棒性就越好。损失函数(一次预测好坏)是经验风险函数（平均意义下模型好坏）的核心部分，也是结构风险函数的重要组成部分。 一些资源：CS231n 2016 通关 第三章-SVM与Softmax 2、损失函数2.1 0-1 Loss 分类错误时损失为1，分类正确 L(Y, f(x))=\begin{cases} 1, & Y \neq f(x)\\ 0, & Y = f(x) \end{cases}2.2 Hinge Loss 折页损失，也称铰链损失，常用于SVM最大间隔法中。将所有不正确分类得分与正确类别（标签）得分之差加1，再与0比较，取最大值求和。1为安全系数，当然可以任意设置，W成比例缩放，损失也会成比例变化，所以分数与W的度量相关。 L(Y, f(x))=\frac{1}{N}\sum_i=1^N\sum_{j\neq y_i}\max{(0, f(x_i)_j - f(x_i)_{y_i}+1)} 问题1：如果在求loss时，允许j=y_i会怎么样？（L加1） 问题2：如果对1个样本做loss时使用对loss做平均，而不是求和，会怎样？（损失绝对值减小，相当于sum乘以常系数，问题1,2均不会影响最终的W） 问题3：若取平方会怎么样？（这其实是二次的hinge loss，在某些情况下会使用。并且某些情况下结果比一次的hinge loss更好，此处使用一次形式。） 问题4：hinge loss的最大最小损失是多少？（0，无穷大） 问题5：通常会以较小较小的值初始化参数w，此时得到的scores接近于0，那么这时候的loss是？(此时正确score与错误score的差接近于0，对于N类，loss的结果是N-1。)存在的问题：若w是损失函数为0，w按比例变化，损失函数值不变。解决办法：引入正则项，对损失函数进行约束$R(w)$，$R(w)$可以衡量w的好坏，因此不仅要求更好的拟合数据，也希望优化w， 同时可以防止过拟合，使得在测试集上效果更好。 L(Y, f(x))=\frac{1}{N}\sum_i=1^N\sum_{j\neq y_i}\max{(0, f(x_i)_j - f(x_i)_{y_i}+1)} + \lambda R(w) 常见的正则项有： L2正则项： L1正则项： 弹性网络（Elastic Net）L1+L2： max-norm regularization： Dropout： 加入正则，对w进行约束，常用的正则有L1、L2。，L1趋于选取稀疏的参数，起到特征选择的作用L2趋于选取数值较小且离散的参数，尽可能的考虑的大部分特征。SVM目标函数即：L2 + hinge loss 2.3 Softmax Loss 在逻辑回归的推导中，它假设样本服从伯努利分布（0-1分布），然后求得满足该分布的似然函数，接着取对数求极值等等。而逻辑回归并没有求似然函数的极值，而是把极大化当做是一种思想，进而推导出它的经验风险函数为：最小化负的似然函数，softmax只是其在多维上的推广，适用于多分类。 得分函数f(x, w)的值score看作是未标准化的对数概率，于是得到每一类的未标准化概率为$e^score$,进一步标准化得到0-1之间的概率，且所以的概率之和为1.大的score代表此score对应图像属于的某一个class的概率大。该函数就是softmax函数： softmax = P(Y = y_i|X = x_i)= \frac{e^{sy_i}}{\sum_j e^{s_j}} 我们要是正确类别对数概率最大，根据损失函数，要是负的正确分类概率最小。 使用似然估计作为loss，本来是似然估计越大越好，但通常loss使用越小时更直观： L_i = -\log{P(Y = y_i|X = x_i)} 即最终表达式：L_i = -\log{\frac{e^{sy_i}}{\sum_j e^{s_j}}} L(Y, f(x))=\frac{1}{N}\sum_{i=1}^N{y_i\dot \log{f(x_i) + (1 - y_i)\log(1-f(x_i))}} 问题1：损失函数最大值最小值？（0，无穷） 问题2：初始化w为很小值时，损失值？（$-log{\frac{1}{CLASSES}}$） softmax与SVM的区别：SVM只考虑支持向量对分类结果的影响，softmax考虑所有数据对结果的影响。 2.5 Absolute Loss 常用于回归任务中。 L(Y, f(x))=\frac{1}{N}\sum_i^N{|f(x_i) - y_i|}2.5 Square Loss 或者均方误差（MSE），常用于回归任务中。 L(Y, f(x))=\frac{1}{N}\sum_i^N{|f(x_i) - y_i|^2}2.6 Exponential Loss 指数损失常用于boosting算法中。 L(Y, f(x))=\sum_i^N{e^{-{y_i}{f(x_i)}}}3、最优化 学习就是个最优化问题，不断更新w，使得损失最小。 3.1 最朴素的思想：随机搜索 计算量大，效果不行，不可取。 3.2 梯度下降 一维函数梯度： \frac{df(x)}{d_x} = \lim_{1 \to \infty}\frac{f(x+h) - f(x)}{h} 梯度检验：，计算梯度的方式有两种：数值梯度（numerical gradient）、解析梯度（analytic gradient）。 数值梯度：根据公式右边计算，优点是容易编程实现，不要求函数可微，然而，缺点也很明显，通常是近似解，同时求解速度很慢，针对多维数据，需反复计算求每一维的梯度值。因此在设计机器学习目标函数时，通常设计成可微的函数，可以快速地通过微积分求解其解析梯度，同时这个梯度是确切解。 解析梯度：通过微积分公式直接对损失函数求导进行计算，无需反复计算，效率高，但易出错，毕竟涉及复杂数学问题。 梯度下降（BGD）、随机梯度下降（SGD）、Mini-batch Gradient Descent、带Mini-batch的SGD 梯度下降（BGD）：通过梯度的负值步长一点一点更新w值，使得损失减少。步长也叫学习率，是一个非常重要的超参数（手工设置，模型不能学）。基于全部数据更新参数，得到全局最优解。 随机梯度下降（SGD）：训练集中随机选取一个样本，更新参数，局部最优解。通常batch_size大小根据GPU内存大小设置。 小批量批梯度下降（mini-batch GD）:训练集中，选取小批量数据更新参数。 *小批量随机梯度下降（mini-batch SGD）：上述两者的结合。]]></content>
      <tags>
        <tag>笔记</tag>
        <tag>cs231n</tag>
        <tag>课程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS31n学习笔记k-NN与线性分类器]]></title>
    <url>%2F2018%2F08%2F20%2FCS31n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C----k-NN%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1、前言 任务：图像分类问题，就是对于输入的图像数据，根据已有的分类标签集合，选出合适的标签对齐进行分类标记，属于监督学习的范畴。虽然该问题对人来说非常简单，但却是计算机视觉领域的核心问题，计算机视觉领域中很多看似不同的问题（比如物体检测和分割），都可以被归结为图像分类问题。 难点：对于计算机来说，一张图像是由[Hight,Width,Channel]组成的张量(Tensor)，张量中的元素为像素值大小，大小在0-255之间的整型，其中0表示全黑，255表示全白。因此图像分类的目标就是：把这些上百万的数字变成一个简单的标签(label)。可想而知，计算机视觉算法所应对的困难与挑战有多大。 1). 视角变化（Viewpoint variation） 2). 大小变化（Scale variation） 3). 形变（Deformation） 4). 遮挡（Occlusion） 5). 光照条件（Illumination conditions） 6). 背景干扰（Background clutter） 7). 类内差异（Intra-class variation） 算法及流程：要应对如此多的变化，采用单一的规则是不可能解决图像分类的问题。那我们不如给计算机“看”大量各种各样猫的照片，然后让计算机自己学习并识别。这种基于大量已标注数据，通过计算机学习来完成某种任务的方法，称为：数据驱动方法。其完整流程包含：输入训练集（已标注数据），学习分类器或者模型，评价分类器质量（验证集）。 2、K-NN K-NN没有显式训练过程，给定一个训练集，对于新输入的测试数据，在训练集中找到与该实例最近邻的K个实例，其中类别数最多的类为该实例的预测标签。 K-NN三要素：距离度量、K值选择以及分类决策。 2.1 距离度量 如何定义两个实例(图像)间的距离？是一种可选择的超参数。 L1 distance（曼哈顿距离）：d_1(I_1,I_2) = \sum_{p}|I_1^p-I_2^p| L2 distance（欧氏距离）：d_2(I_1,I_2) = \sqrt{\sum_{p}|I_1^p-I_2^p|^2} Lp distance（闵可夫斯基距离）：d_p(I_1,I_2) = (\sum_{p}|I_1^p-I_2^p|^p)^\frac{1}{p} $L_\infty$ distance（切比雪夫距离）：d_\infty(I_1,I_2) = \max_{p}|I_1^p-I_2^p| 马氏距离：d(\vec x,\vec y)=\sqrt{(\vec x-\vec y)^TS^{-1}(\vec x-\vec y)} 余弦距离：d(\vec x,\vec y)=1 - \frac{\vec x .\vec y}{|\vec x||\vec y|} 汉明距离：字符串x变成y所需要的最小的替换次数 对于图像的L1距离计算： 选择L1距离的K-NN代码如下：123456789101112131415161718192021222324252627import numpy as npclass NearestNeighbor(object): def __init__(self): pass def train(self, X, y): """ X is N x D where each row is an example. Y is 1-dimension of size N """ # the nearest neighbor classifier simply remembers all the training data self.Xtr = X self.ytr = y def predict(self, X): """ X is N x D where each row is an example we wish to predict label for """ num_test = X.shape[0] # lets make sure that the output type matches the input type Ypred = np.zeros(num_test, dtype = self.ytr.dtype) # loop over all test rows for i in xrange(num_test): # find the nearest training image to the i'th test image # using the L1 distance (sum of absolute value differences) distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1) min_index = np.argmin(distances) # get the index with smallest distance Ypred[i] = self.ytr[min_index] # predict the label of the nearest example return Ypred 2.2 k值的选择 另一个超参数，k值选择会对算法结果产生非常大的影响。 如果k值较小，相当于用较小的领域中的训练实例进行预测，“学习”的近似误差会减小，只有与输入实例较近的训练实例才会对预测结果起作用。但缺点是估计误差会增大，即预测结果对近邻点实例非常敏感，若近邻实例为噪声就会导致错误的预测结果。极端地，若k=1，预测结果为最近领点所属类别。 如果k值较大，相当于用较大的领域中的训练实例进行预测，优点在于“学习”的估计误差会减小，但缺点是近似误差会增大，这时与输入实例较远的（不相似的）训练实例也会起作用。极端地，若k=N，模型过于简单，完全忽略了训练集中有用的信息，无论输入实例是什么，预测结果均为训练集中类别最多的类。 那么K值如何选择呢？简单的，尝试各种不同的参数，选择效果最好的。但是，如果只是在测试集评价效果最好是不可取的。一是因为测试集为最终模型泛化性能的评价而存在的；二是因为很可能会在测试集上过拟合了，无法在其他新数据达到很好泛化结果。 因此，常采用留一法或k折交叉验证法（5折/10折居多）来选取k值。 2.3 分类决策 常采用多数表决法，等价于经验风险最小化。 2.4 缺点 1). 速度慢，K-NN测试速度随着训练集规模线性增长，CNN相反：训练时间长，测试时间短（固定的计算）。 2). 复杂度高，如何降低最近邻分类器的计算复杂度也是研究的热门，在预处理阶段建立kd树或使用k-means聚类等，加速在数据集中查找最近邻的效率。近似最近邻算法（Approximate Nearest Neighbor (ANN) algorithms）如(FLANN)，牺牲了一定的最近邻精度来换取空间/时间复杂度的降低。 3). 不适用于维数大、容量大的数据，最近邻分类器在某些情况下可能会是一种好的选择，特别是数据维度比较低、数据量较小的时候，但是对于图像分类问题来说它基本不适合。原因之一是图像是高维物体（包含很多像素），在高维空间中进行距离运算通常不可靠。 3、线性分类器 相比于K-NN，线性分类器是基于参数化方法得到分类结果。 $score = f(x, W) = Wx+b$ Ｘ为输入图像3072个输入神经元[3072, 1]，Ｗ为权重[10, 3072]（学习的参数）$score$[10, 1]为预测得分。b[10, 1]为偏置。 具体计算例子： 将在CIFAIR数据集训练得到的W可视化，10类的特征权重如下图： a）马头和汽车存在左右方向，可看出对应参数出现两个头的情况。 问题： a）对于线分类器，最难分类的数据样本是哪些？ 实质为不同位置的颜色带权混合，因此针对不同位置、不同纹理难识别。]]></content>
      <tags>
        <tag>笔记</tag>
        <tag>cs231n</tag>
        <tag>课程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS31n学习笔记计算机视觉发展史]]></title>
    <url>%2F2018%2F08%2F19%2FCS31n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80----%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%8F%91%E5%B1%95%E5%8F%B2%2F</url>
    <content type="text"><![CDATA[1、前言 CS231n是斯坦福大学李飞飞团队2015年冬季学期开始开设的一门基于神经网络或者说卷积神经网络的计算机视觉课程，全称是CS231n: Convolutional Neural Networks for Visual Recognition，如今完全成为了一门明星课程，也是每一个CVer入门的必学课程之一。目前，已经有2015冬季版，2016冬季版，2017春季版，2018春季版（视频未公布），每学期的视频更新都会引起一波充电热潮。 互联网和传感器的发展，特别是视觉传感器，如：手机摄像头，数码相机，视频监控，行车记录仪等等，引发了视觉信息的大爆炸。不得不说，我们完全进入到了一个视觉时代，一个图片、视频信息爆炸的时代。但是这些信息也是最难以被利用的信息，我们称其为“互联网中的暗物质”。就像银河系中85%的质量属于暗物质和暗能量，难以被检测和利用。YouTube每60秒就会接受150小时以上的视频上传，我们根本不可能靠人眼给如此大量的数据进行标注、分类。那么如何对这些数据进行标记、分类、索引等工作，进而利用这些数据来做广告、检索或者其他操作。唯一的希望就是利用计算机去帮我们完成这项工作，运用计算机视觉技术对图片进行标签、分类，对视频进行理解。如何更好地利用这些海量数据，如何应对“暗物质”的挑战，如何让计算机更好地理解这个世界，这就是计算机视觉要解决的问题。 计算机视觉是一门跨学科的课程，所以，我们面对的问题，建模方式也必将是跨学科的，像工程学、物理学、生物学、心理学、计算机科学和数学都有着密切关系。 一些资源：http://cs231n.github.io/classification/ 2、计算机视觉简史2.1 计算机视觉的诞生 第一只眼的诞生：在五亿四千三百万年前，单细胞生物就已在地球上出没，当时的动物物种只有三个动物门。而在短短的五百万年后(这段时期仅占生物演化史的千分之一)，这三个动物门的物种突然演化成三十八个动物门，几乎现今所有动物的祖先，全在一瞬间蜂涌而出。这个物种快速暴增的现象发生在寒武纪初期，称为寒武纪大爆发，其原因至今仍是未解之谜。其中，Andrew Parker的“光开关理论”最具说服力，他研究发现，当时由于一个偶然的原因，浅海和大气中的化学物质发生了变化，使得浅海和大气的透明度大大增加。随着大量的光线进入海洋，于是动物开始进化出接收光的器官——眼睛。约5.4３亿年前出现的三叶虫正是第一批演化出真正眼睛的动物，刚进化的眼睛非常非常的简陋就像针孔相机，甚至没有晶体状，只能接收一点光线和感知环境信息。该理论认为正是眼睛的进化，引发了生命体之间的进化竞赛，使得那些具备最佳视觉的生物才最有可能生存下来。眼睛的出现，可能是地球上寒武纪生命大爆发的主要原因。 达芬奇的相机：16世纪文艺复兴时期，达芬奇发明了“照相暗盒”（camera obscura），开始用来获取真实世界中的图像信息，这种早期的照相设备并不能产生出照片，只能方便艺术家描绘物体的比例。但这便是现代视觉工程技术的开端了，人们开始复制我们所看到的信息，不过这并没有涉及到试图去理解所看到的信息。从此之后，视觉技术取得一定的进步，如：电影技术、柯达商用相机产品、摄像机产品等等。 大脑视觉处理:1959年，Huber&amp;Wiesel研究生物的大脑是如何处理视觉信息的。他们发现，大脑并不是对整体目标进行处理，而是从简单的形状（例如，边缘）开始处理视觉信息。在视觉处理的第一步，基础视觉区的神经元按一列一列组织起来，每一列神经元只“喜欢”某一种特定的形状,某种线条的简单组合。1981年两位科学家凭借这个贡献获得了诺贝尔奖，这是视觉领域一项极其重要的成就。 方块世界：现代计算机视觉领域的先驱是Lary Roberts在1963年的论文，名为“方块世界”Block World，也是计算机视觉第一篇博士论文。视觉信息处理是基于边缘好形状，是边缘决定了形状。 计算机视觉的诞生：计算机视觉诞生于1966年夏季，MIT成立了人工智能实验室，其中一名教授开始着手研究计算机视觉问题。至此，计算机视觉成为AI领域增长最快的一个领域，计算机视觉顶级大会CVPR和ICCV每年都有来及自全世界的进行这方面研究的研究人员。 2.2 近现代发展 VISION：David Marr写了一本非常有影响力的书籍VISION，并给了我们第二个非常重要的观点（第一个为Huber&amp;Wiesel认为的视觉处理是从一些简单的形状开始，而不是整体目标）：视觉是分层的。复杂的视觉处理可以基于这两个观点进行，即从简单形状开始，并建立一个分层模型。David Marr认为图像结构可以分为多层，第一层为简单的边缘结构（同Huber&amp;Wiesel）他叫其为原始草图，接下来他称之为2.5D，这里将2D图像信息调整为包含真实世界的3D信息。第三层为3D真实世界的模型。这是一个高度抽象的架构，并不能指引建立相应数学模型，但这是一个非常重要的、宏观的概念思想。基于David Marr的思考方式，开始涌现出一波视觉识别算法，即重建3D模型，以便于进一步识别。其中，Generalized Cylinder模型（1979年）认为世界由简单形状组合，通过不同角度观察而来。Pictorial Structure模型（1973年），其认为物体有简单的部分组成，如人脸由眼镜鼻子和嘴组成，各部分之间通过“弹簧”连接，允许之间出现一定形变。 Normalized Cut：第一次使用现实世界照片解决彩色图像分割问题。感知分组：视觉领域最为重要的问题。 VJ人脸检测器：第一个转化为智能人脸检测的产品，应用于富士康相机2006年的数码相机产品中。基于haar特征+adboost分类器。也是第一项在计算机上可以实时运行的计算机视觉方面的研究成果。虽然这并不是这个时期的唯一成果，但这件成果反应了计算机视觉领域研究聚焦的一次变迁，不再是David Marr的重建3D模型再识别，而是直接识别“物体是什么”。该成果将研究的焦点聚焦到识别领域，这个趋势，将计算机视觉带回了人工智能领域。 Feature： a）SIFT（David Lowe，1999年）：尺度不变特征转换(Scale-invariant feature transform)，步骤：尺度空间极点检测—关键点精确定位—关键点的方向确定—特征向量的生成 b）SPM（Lazebnik, Schmid &amp; Ponce, 2006年）：空间金字塔匹配（Spatial Pyramid Matching)，Spatial：将图像分成若干块(sub-regions)，分别统计每一子块的特征，最后将所有块的特征拼接起来，形成完整的特征。Pyramid：在分块的细节上，采用了一种多尺度的分块方法，即分块的粒度越大越细(increasingly fine)，呈现出一种层次金字塔的结构。Matching：匹配 c）HOG（Dalal &amp; Triggs, 2005年）：梯度方向直方图(Histogram of Oriented Gradient)，步骤：全局图像归一化—计算图像梯度—统计局部图像梯度信息—归一化—生成特征描述向量 d）DPM（Felzenswalb, McAllester, Ramanan,2009年）：可变形的组件模型（Deformable Part Model），88分辨率的根滤波器（Root filter）+ 44分辨率的组件滤波器（Part filter）。 2.3 深度学习的时代 数据： ａ）MNIST(Modified National Institute of Standards and Technology, Yann LeCun 1998年),70,000张扫描的手写数字字体照片（每张为0-9中的一个数字）。 ｂ）Pascal VOC(PASCAL Visual Object Challenge,Everingham et al. 2006-2012年),包含20类的目标检测数据集，10000级别的照片数量。 ｃ）ImageNet(Deng, Dong, Socher, Li, Li, &amp; Fei-Fei, 2009年)，包含2万分类，千万级别（5000万）的识别检测数据集。从2010年开始，每年举行图像识别比赛：1,000 类目标，1,431,167张图像，被称为计算机视觉领域的奥铃匹克竞赛。2012年卷积神经网络（CNN）以巨大优势取得冠军，深度学习再次掀起研究热潮，成为深度学习革命的开端。 模型： ａ）LeNet:(Yann LeCun 1998年)，结构：conv+pooling+conv+pooling+conv+FC+FC，激活函数为sigmoid，用于MNIST手写字体识别。 ｂ）AlexNet:(Krizhevsky et al. 2012年)，结构：conv1+pooling+conv2+pooling+conv3+conv4+conv5+fc6+fc7+fc8，激活函数Relu，运用多个GPU训练。 ｃ）ZFNet：(Matthew D. Zeiler et al. 2013年)，结构：AlexNet一些参数的改动，对CNN提取特征进行可视化。 ｄ）GoogLeNet：(Szegedy et al. 2014年)，结构：inception结构。 ｅ）VGG：(Simonyan 2014年)，结构：（VGG16）conv1+conv2+pooling+conv3+conv4+pooling+conv5+conv6+conv7+pooling+conv8+conv9。+conv10+pooling+conv11+conv12+conv13+pooling+FC14+FC15+FC16。 ｆ）ResNet：(Kaiming He et al. 2015年)，结构：residual block。 ｇ）DenseNet：(Huang et al. 2017年)，结构：ResNet的密集链接。 硬件： NVIDIA GPU计算能力。 3、课程主题 CS231n关注视觉识别问题—图像分类(image classification)，以及大量相关问题，如：目标检测(object detection), 图像描述(image captioning)…。 计算机视觉解决的问题远不止识别问题，还有一大堆亟待解决的问题，如：密集标记、感知分组、3D场景识别，动作理解等等。计算机视觉的终极目的：理解，让计算机像人一样理解这个世界，并让世界变得更美好。]]></content>
      <tags>
        <tag>笔记</tag>
        <tag>cs231n</tag>
        <tag>课程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BAT机器学习面试题库（1-100）]]></title>
    <url>%2F2018%2F07%2F20%2FBAT%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98%E5%BA%93%EF%BC%881-100%EF%BC%89%2F</url>
    <content type="text"><![CDATA[为了求职笔试面试，需恶补基础、算法原理，于是仔细研读了七月在线发布的BAT机器学习面试1000题系列，也添加了一些自己的理解或来自其他博客的答案，以下内容均来自BAT机器学习面试1000题系列。该文为本人的阅读笔记，主要是为了记忆和自查。 前言July我又回来了。 之前本博客整理过数千道微软等公司的面试题，侧重数据结构、算法、海量数据处理，详见：微软面试100题系列，今17年，近期和团队整理BAT机器学习面试1000题系列，侧重机器学习、深度学习。我们将通过这个系列索引绝大部分机器学习和深度学习的笔试面试题、知识点，它将更是一个足够庞大的机器学习和深度学习面试库/知识库，通俗成体系且循序渐进。 此外，有四点得强调下： 虽然本系列主要是机器学习、深度学习相关的考题，其他类型的题不多，但不代表应聘机器学习或深度学习的岗位时，公司或面试官就只问这两项，虽说是做数据或AI相关，但基本的语言（比如Python）、编码coding能力（对于开发，编码coding能力怎么强调都不过分，比如最简单的手写快速排序、手写二分查找）、数据结构、算法、计算机体系结构、操作系统、概率统计等等也必须掌握。对于数据结构和算法，一者 重点推荐前面说的微软面试100题系列（后来这个系列整理成了新书《编程之法：面试和算法心得》），二者 多刷leetcode，看1000道题不如实际动手刷100道。 本系列会尽量让考察同一个部分（比如同是模型/算法相关的）、同一个方向（比如同是属于最优化的算法）的题整理到一块，为的是让大家做到举一反三、构建完整知识体系，在准备笔试面试的过程中，通过懂一题懂一片。 本系列每一道题的答案都会确保逻辑清晰、通俗易懂（当你学习某个知识点感觉学不懂时，十有八九不是你不够聪明，十有八九是你所看的资料不够通俗、不够易懂），如有更好意见，欢迎在评论下共同探讨。 关于如何学习机器学习，最推荐机器学习集训营系列。从Python基础、数据分析、爬虫，到数据可视化、spark大数据，最后实战机器学习、深度学习等一应俱全。 另，本系列会长久更新，直到上千道、甚至数千道题，欢迎各位于评论下留言分享你在自己笔试面试中遇到的题，或你在网上看到或收藏的题，共同分享帮助全球更多人，thanks。 BAT机器学习面试1000题系列 1.请简要介绍下SVM。]]></content>
      <tags>
        <tag>面试</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018搜狐内容识别算法大赛总结]]></title>
    <url>%2F2018%2F06%2F20%2F2018%E6%90%9C%E7%8B%90%E5%86%85%E5%AE%B9%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9B%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.前言直击搜狐内容识别算法总决赛 2. 代码说明 针对该比赛，我们使用的是python3和java8的语言环境，代码中主要涉及的包有：numpy、pandas、sklearn、gensim、tensorflow、keras、xgboost、HanLP。代码中主要分为特征提取、常用工具与模型构建的三类文件，下面对各代码文件作简要说明： data目录： 数据及模型存储路径。 keras_retinanet目录：目标检测算法retinanet代码目录（最终未采用）。 utils目录：HanLP工具java代码，包含分词代码与词性特征提取代码，由于java代码分词速度远比pyhanlp快，最终采用java代码做分词和词性特征提取。 preprocess.py：主要实现对数据进行预处理：过滤只有图片没有片段的1类新闻、数据清洗、文本分词（jieba和HanLP）。 feat_TF-IDF_stack.py：TF-IDF stacking特征生成，包含TF-IDF特征提取，各基础模型（LogisticRegression、MultinomialNB、BernoulliNB）的5折训练及训练集特征提取，测试集stacking特征提取。每个模型输出[num_samples x 3]的特征。 feat_nature_stack.py：词性stacking特征生成 ，根据java代码输出的词性统计特征，运用各基础模型（LogisticRegression，MultinomialNB，BernoulliNB）对训练集做词性stacking特征提取，测试集stacking特征提取。每个模型输出[num_samples x 3]的特征。 feat_w2v_model.py：词向量特征提取提取，输出包括：[num_samples x 300]的求和词向量，[num_samples x 300]的均值词向量以及TF-IDF与词向量的权值词向量。最终采用均值词向量作为文本的词向量特征。 feat_d2v_model.py：Doc2vec stacking特征，主要提取了Doc2vec两种训练方法的特征，运用神经网络分别做5折stacking，为训练集和测试集提取两类[num_samples x 3]的stacking特征。 feat_statistic.py：统计特征提取，主要包含：标题及文本长度、图片数量、文本中关于钱出现的次数、网站出现次数、电话出现次数、日期出现次数、营销词汇出现次数等各类统计特征。 get_segs.py： 为预测为1类的新闻添加营销片段。 predict.py：加载模型预测并输出提交结果文件。 tools_py3.py：主办方提供的tool.py对应的python3版本，来及群内分享。 param.py：各类参数配置代码：jieba、hanlp分词工具选择，是否去停词，是否训练，各类数据、模型保存路径。 utils.py：主要工具代码：日志打印、数据读取、去除BOM、sklearn模型的加载与保存、评估函数 STFIWF.py：改进的TF-IDF特征提取代码，考虑标签与词频的关系，主要参考自[here]。 detect.py：图片二维码、小程序、电话、网址检测代码（最终未采用）。 xgb_blending.py模型线下验证、模型训练代码。 3. 最优结果生成文档1). 模型说明 分类模型：我们主要运用了四类基础模型对部分特征做stacking，输出若干个[num_samples x 3]的stacking特征，拼接 上均值词向量特征与文本统计特征，用于最后xgb模型训练。针对TF-IDF与词性这类稀疏特征，我们采用LogisticRegression、MultinomialNB和BernoulliNB的基础模型，而对于Doc2vec的dbow与dm特征，我们使用keras搭建的神经网络模型。最后参数抖动训练五个xgb模型，将5个xgb模型的输出结果求均值作为最后的输出结果，按照概率最大得到最终类别预测结果。 片段提取：对于营销片段提取，我们采用规则匹配的方法。即：针对，预测为1类的新闻文本，直接判断测试集中新闻文本是否包含训练集中的营销片段，若能匹配到，则提取作为营销片段的预测输出。 模型结构如下：模型结构图 2). 特征说明 我们从 ５个方面对新闻文本进行特征构建，分别是：基于TF-IDF的特征、基于词性的特征、基于 Word2Vec 的特征、基于 Doc2Vec 的特征和文本统计特征。 基于TF-IDF的特征 TF-IDF（term frequency–inverse document frequency）是一种用于信息检索与文本挖掘的常用加权技术。tf-idf 是一种统计方法，用以评估一字词对于一个文档集或一个语料库中的其中一份文档的重要程度。字词的重要性随着它在文档中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。 TF-IDF的不足在于：单词在文档中的出现次数TF对于整体权重影响过大；没有考虑到单词在不同类间的分布差异。于是，我们没有采用sklearn中的TfidfVectorizer 提取特征，而是参考[here]使用改进后的TfidfVectorizer 提取文本TF-IDF特征。但是TF-IDF属于高维稀疏向量，直接使用树模型进行训练不仅速度较慢且效果不一定很好。于是，我们采用了一种比较流行的做法，就是做一层 stacking，将高维稀疏特征转化为低维稠密向量。在这里我们尝试了很多个基础模型，最终使用了LogisticRegression，MultinomialNB和BernoulliNB。 基于词性的特征 我们使用了HanLP汉语言处理工具包提取了文本的词性特征，共148类，并统计各类词性出现的次数与比例、以及整体的信息熵。词性统计特征同样拥有TF-IDF稀疏的特性，于是我们采用了同样的三个基模型对词性统计特征做了一层stacking。 基于 Word2Vec 的特征 Word2Vec 方法，可以将词语直接表示成一个固定长度的向量。对于Word2Vec特征，我们选定的维数为300维，并将训练数据（打标数据与未打标数据）中词频低于5的词语过滤掉。一篇文档的词向量特征，我们尝试了对每个词求和、求均值、基于TF-IDF加权的操作。最终由于词向量求和效果不好，加权操作计算量过大而选择均值词向量作为文档的Word2Vec 特征向量。 基于 Doc2Vec 的特征 使用 Doc2Vec 方法，可以将文档直接表示成一个固定长度的向量。根据训练文档向量的网络结构的不同，可以分为 Distributed Memory（DM）与 Distributed Bag of Words（DBOW）两种模型。其中 DM 模型不仅考虑了词的上下文语义特征，还考虑到了词序信息。DBOW 模型则忽略了上下文词序信息，而专注于文档中的各个词的语义信息。我们同时采用了 DBOW 和 DM 这两种模型构建文档向量，希望能够保留文档中完整的信息。 我们选择Doc2Vec的维数为300，并采用迭代的训练方法，进行多次重复训练，每一次都需要对训练数据（打标数据与未打标数据）重新打乱，以提高分类精度，DBOW 模型的迭代次数为 5，DM 模型的迭代次数为 10。我们对这两类文档向量分别做了一层 stacking，使用了一个简易的神经网络模型，只有一层 300 维的隐含层，进行训练并构建下一层模型需要的特征。 文本统计特征 本次竞赛要求尽可能识别营销类别的文章，于是营销词汇如：“优惠”、“特惠”、“加盟”、“利润空间大”、“免费”、“实惠””……；同时，我们发现1类文章多为转载文章，片段中的词汇如：“来源”、“转载”、“出自”，“版权”……；这些词汇对文本分类会起着重要的作用。我们基于训练数据建立了两个字典，并统计标题、文本中出现第一类词汇的次数，内容文本最后一句中第二类词汇出现的次数。另外还统计了文本长度、标题长度、图片数量、关于钱的内容、时间、日期、微信、QQ、ID等各类特征。3). 提升改进 更加细致的数据清洗工作，运用正则表达式做各种文本替换:时间、日期、电话、网址、微信、QQ、ID、关于钱的内容、打折信息、【】《》里的内容等。 选择更好的基础模型，在若干个基础模型中选择了较优的几个模型。 修改、增加部分统计信息。 4). 值得学习的方案 第一名开源方案]]></content>
      <tags>
        <tag>比赛</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开始我的第一篇hexo博客]]></title>
    <url>%2F2018%2F05%2F23%2F%E5%BC%80%E5%A7%8B%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87hexo%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2018%2F05%2F23%2Ftest%2F</url>
    <content type="text"><![CDATA[var ap = new APlayer({ element: document.getElementById("aplayer-PwlFQCeh"), narrow: false, autoplay: false, showlrc: false, music: { title: "她的睫毛", author: "周杰伦", url: "http://home.ustc.edu.cn/~mmmwhy/%d6%dc%bd%dc%c2%d7%20-%20%cb%fd%b5%c4%bd%de%c3%ab.mp3", pic: "http://home.ustc.edu.cn/~mmmwhy/jay.jpg", lrc: "" } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap);]]></content>
  </entry>
  <entry>
    <title><![CDATA[MobaXterm 基本的使用方法]]></title>
    <url>%2F2018%2F05%2F21%2FMobaXterm-%E5%9F%BA%E6%9C%AC%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[小白利用hexo和github搭建博客前言： 纯新手小白，转行自学java途中，想写点东西，记录自己的成长过程。因此，花了一天的时间，游览各个大佬的文章，学着用hexo和github搭建自己的博客。 参考链接：我是如何利用Github Pages搭建起我的博客，细数一路的坑Hexo + yilia 搭建博客可能会遇到的所有疑问Hexo+Github实现相册功能 Hexo + yilia 主题实现文章目录号外号外！解决github+hexo+yilia评论插件的问题！！！ 一、所需要的环境安装Node.js()http://nodejs.cn/download/配置环境变量，windows下安装配置环境，一键完成很简单。 安装git（必须）可以查看廖雪峰老师的git教程https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000学习安装下载地址：https://git-for-windows.github.io/注册github账号:https://github.com/配置SSH-key:https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001374385852170d9c7adf13c30429b9660d0eb689dd43a000。创建名为userName.github.io的仓库,userName是你申请的用户名。 二.安装hexo安装Hexo: 右键git bash,输入npm install -g hexo初始化Hexo: 自定义创建一个文件夹（用来放置你的博客）,点击该文件夹,输入 &gt; hexo init3.然后生成部署文件，启动本地服务 hexo g 或者hexo generate hexo s 或者hexo server，可以在http://localhost:4000/ 查看 至此hexo已经安装完毕了,我安装过程中出现了以下问题： 在hexo install过程中可能出现npm WARN deprecated swig@1.4.2: This package is no longer maintained只是说这个包不再维护了，后面好像并不影响使用，当然你也可以npm -g install npm，更新安装。 三、布置博客熟悉git的简单操作选中你的文件夹 git init ，创建仓库git add.``git commit -m”标记”，提交文件修改 git remote add origin https://github.com/Scyzin/scyzin.github.io.git 与你的github仓库连接git push -u origin master，将你的修改上传到github上。博客主题更换hexo默认的主题是landscape，在themes文件夹下，可以使用别人开发好的主题，这里有很多，我使用的是这一个: https://github.com/litten/hexo-theme-yilia下载之后将文件夹整个复制到D:\blog\themes目录下，再修改D:\blog 的下_config.yml文件里的theme：theme: hexo-theme-yilia。部署配置配置到github对应的仓库中: 1.为hexo安装git插件:npm install —save hexo-deployer-git，否则会出现 hexo d时会出现 ERROR Deployer not found: git2.修改D:\blog 的下_config.yml文件 deploy:type: gitrepo: https://github.com/Scyzin/scyzin.github.io.gitbranch: master加入如下配置：冒号后面都必须有空格。 Hexo配置文件说明:D:\blog`的下_config.yml常用的配置熟悉下就会了，这里可以选择学习一个扩展配置。http://blog.csdn.net/u013082989/article/details/70144934?locationNum=3&amp;fps=1hexo d，将博客发布在github.io上。至此你就可以直接通过scyzin.github.io访问你的博客。当然你也可以选择购买域名，绑定自己的地址访问。 四、hexo常用命令hexo new “postName” #新建文章其中my new post为文章标题，执行命令后，会在项目\source_posts中生成my new post.md，用markdown编辑器打开编辑就行了。 当然，也可以直接在\source_posts中新建一个md文件，我就是这么做的。** hexo new page “pageName” #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭server）hexo deploy #将.deploy目录部署到GitHubhexo help # 查看帮助简写: hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deployexo version #查看Hexo的版本 一些遇到的问题支持公式：https://www.jianshu.com/p/7ab21c7f0674]]></content>
      <tags>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[马上金融---图像去污比赛总结]]></title>
    <url>%2F2018%2F05%2F18%2F%E9%A9%AC%E4%B8%8A%E9%87%91%E8%9E%8D---%E5%9B%BE%E5%83%8F%E5%8E%BB%E6%B1%A1%E6%AF%94%E8%B5%9B%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[一、前言 前段时间参加了一个图像的比赛，起因于实验室老师在群里发了关于马上金融AI算法大赛的链接，从而得知马上金融这个比赛（后来公司也来学校宣讲了）。由于本人研究方向是图像处理与深度学习这一块，加上之前看过深度学习去雨的相关内容，想来也应该有很多相同之处，于是决定尝试一波。最后很意外地得到了第一名。]]></content>
      <tags>
        <tag>比赛</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017搜狐图文匹配算法大赛总结]]></title>
    <url>%2F2017%2F06%2F18%2F2017%E6%90%9C%E7%8B%90%E5%9B%BE%E6%96%87%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9B%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[一、前言 爱搞事儿的师姐(”▽“)突然发来一条链接，问我要不要一起搞事儿参加个比赛，怀着初生牛犊不怕虎的想法，折腾就折腾吧，于是参加了搜狐图文匹配这个比赛，这也是搜狐第一届算法大赛。运气还不错，得了一个周冠军，全实验室吃了一顿大餐，最后也拿到一个还不错的名次：第4名 二、赛题介绍三、解题思路四、其他方案 其他队伍方案：SOHU图文匹配竞赛-方案分享 四、总结展望 由于刚接触深度学习，自然语言处理这些新的方向，很多东西做的不够完善，没有尝试端到端的建模方法。同时，由于自身能力不足，很多想法没能实现。不过，能到决赛现场跟很多优秀的同学学习交流，知道了很多其他的方法，如：OCR、各种文本编码（TF-IDF、LSI、LDA）；对了，还有师兄强大的spark，能把我几十个小时的代码加速到1.5h。也见识了帝都的风貌（很遗憾有事儿先回了o(╥﹏╥)o），感觉运气很不错，很满意了。希望以后好好学习学习这方面的东西，不愧于研究生这三年。最后，附上视频与合照，以作纪念！！！ 2017搜狐图文匹配算法大赛精彩回顾 决赛合影留念]]></content>
      <tags>
        <tag>比赛</tag>
        <tag>总结</tag>
      </tags>
  </entry>
</search>
